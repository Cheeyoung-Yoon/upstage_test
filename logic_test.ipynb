{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "A100",
      "mount_file_id": "1geoDYZNW4WDuw-XCSmublBXJA-_nZ6e_",
      "authorship_tag": "ABX9TyMcz++NPw7E/QNGNzTqL7R9",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Cheeyoung-Yoon/upstage_test/blob/main/logic_test.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XnVrS66-VtUO"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "FWxd5mMvFS-U"
      },
      "outputs": [],
      "source": [
        "from dataclasses import dataclass\n",
        "from typing import List\n",
        "\n",
        "DEFAULT_LABEL_LIST: List[str] = [\n",
        "    'no_relation','org:top_members/employees','org:members','org:product','per:title',\n",
        "    'org:alternate_names','per:employee_of','org:place_of_headquarters','per:product',\n",
        "    'org:number_of_employees/members','per:children','per:place_of_residence',\n",
        "    'per:alternate_names','per:other_family','per:colleagues','per:origin',\n",
        "    'per:siblings','per:spouse','org:founded','org:political/religious_affiliation',\n",
        "    'org:member_of','per:parents','org:dissolved','per:schools_attended',\n",
        "    'per:date_of_death','per:date_of_birth','per:place_of_birth','per:place_of_death',\n",
        "    'org:founded_by','per:religion'\n",
        "]\n",
        "\n",
        "@dataclass\n",
        "class TrainConfig:\n",
        "    model_name: str = \"klue/roberta-base\"\n",
        "    output_dir: str = \"./runs\"\n",
        "    num_train_epochs: int = 5\n",
        "    learning_rate: float = 2e-5\n",
        "    per_device_train_batch_size: int = 16\n",
        "    per_device_eval_batch_size: int = 16\n",
        "    warmup_ratio: float = 0.05\n",
        "    weight_decay: float = 0.01\n",
        "    logging_steps: int = 500\n",
        "    save_steps: int = 500\n",
        "    eval_steps: int = 500\n",
        "    save_total_limit: int = 2\n",
        "    load_best_model_at_end: bool = True\n",
        "    seed: int = 42\n",
        "    max_length: int = 256\n",
        "    fp16: bool = True\n",
        "    es_patience: int = 2\n",
        "\n",
        "    # ÌëúÌòÑ/ÌÜ†ÌÅ∞\n",
        "    inline_markers: bool = True\n",
        "    marker_variant: str = \"typed\"   # [\"typed\",\"plain\"]\n",
        "\n",
        "    # ÏÜêÏã§/Ï†ïÍ∑úÌôî/Ïä§ÏºÄÏ§ÑÎü¨\n",
        "    label_smoothing: float = 0.1\n",
        "    lr_scheduler_type: str = \"cosine\"\n",
        "    use_class_weight: bool = False\n",
        "    use_cb_loss: bool = False\n",
        "    use_focal: bool = False\n",
        "    focal_gamma: float = 2.0\n",
        "    rdrop_alpha: float = 0.0\n",
        "\n",
        "    # ÏµúÏ†ÅÌôî\n",
        "    use_llrd: bool = False\n",
        "    llrd_decay: float = 0.95\n",
        "\n",
        "    # Íµ¨Ï°∞/Ìä∏Î¶≠\n",
        "    use_marker_head: bool = True\n",
        "    use_erpe: bool = False\n",
        "    erpe_dim: int = 32\n",
        "    use_fgm: bool = False\n",
        "    fgm_eps: float = 1e-3\n",
        "\n",
        "    # ÌïòÎìú ÎÑ§Í±∞Ìã∞Î∏å\n",
        "    use_hardneg: bool = False\n",
        "    hardneg_tau: float = 0.55\n",
        "    hardneg_boost: float = 2.0"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# data_plus.py\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import re\n",
        "import ast\n",
        "from typing import Optional\n",
        "\n",
        "class RE_Dataset(torch.utils.data.Dataset):\n",
        "    \"\"\" tokenized dict + labels (+ optional weights) \"\"\"\n",
        "    def __init__(self, pair_dataset: dict, labels, weights: Optional[np.ndarray]=None):\n",
        "        self.pair_dataset = pair_dataset\n",
        "        self.labels = labels\n",
        "        self.weights = weights if weights is not None else np.ones(len(labels), dtype=np.float32)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = {k: v[idx].clone().detach() for k, v in self.pair_dataset.items()}\n",
        "        item[\"labels\"] = torch.tensor(self.labels[idx])\n",
        "        return item\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "def preprocessing_dataset(df: pd.DataFrame) -> pd.DataFrame:\n",
        "    def pick_word(s):\n",
        "        try:\n",
        "            d = ast.literal_eval(s) if isinstance(s, str) else s\n",
        "            return d.get(\"word\"), d.get(\"type\")\n",
        "        except Exception:\n",
        "            return None, None\n",
        "    subj_words, obj_words = [], []\n",
        "    for s, o in zip(df[\"subject_entity\"], df[\"object_entity\"]):\n",
        "        sw, _ = pick_word(s); ow, _ = pick_word(o)\n",
        "        subj_words.append(sw or \"<SUBJ>\"); obj_words.append(ow or \"<OBJ>\")\n",
        "    out = pd.DataFrame({\n",
        "        \"id\": df[\"id\"],\n",
        "        \"sentence\": df[\"sentence\"],\n",
        "        \"subject_entity\": df[\"subject_entity\"],\n",
        "        \"object_entity\": df[\"object_entity\"],\n",
        "        \"subj_word\": subj_words, \"obj_word\": obj_words,\n",
        "        \"label\": df[\"label\"],\n",
        "    })\n",
        "    return out\n",
        "\n",
        "\n",
        "def load_data(csv_path: str) -> pd.DataFrame:\n",
        "    # Accept a single path or (path,) tuple/list and normalize to string\n",
        "    if isinstance(csv_path, (list, tuple)):\n",
        "        csv_path = csv_path[0]\n",
        "    return preprocessing_dataset(pd.read_csv(csv_path))\n",
        "\n",
        "\n",
        "def _inline_mark(sentence: str, s_word: str, o_word: str, s_type: Optional[str], o_type: Optional[str], use_type: bool, use_unk: bool):\n",
        "    # Ï≤´ Îì±Ïû•Îßå ÏπòÌôò (Îã®Ïñ¥ Í≤ΩÍ≥Ñ Í≥†Î†§)\n",
        "    def repl_first(text, pat, repl):\n",
        "        m = re.search(rf'(?<!\\w){re.escape(pat)}(?!\\w)', text)\n",
        "        if not m: return text\n",
        "        return text[:m.start()] + repl + text[m.start():m.end()].replace(pat,\"\") + text[m.end():]\n",
        "\n",
        "    if use_type:\n",
        "        s_type = s_type or (\"UNK\" if use_unk else None)\n",
        "        o_type = o_type or (\"UNK\" if use_unk else None)\n",
        "        if s_type and o_type:\n",
        "            s_tag = f\"[E1-{s_type}]{s_word}[/E1]\"\n",
        "            o_tag = f\"[E2-{o_type}]{o_word}[/E2]\"\n",
        "        else:\n",
        "            s_tag = f\"[E1]{s_word}[/E1]\"; o_tag = f\"[E2]{o_word}[/E2]\"\n",
        "    else:\n",
        "        s_tag = f\"[E1]{s_word}[/E1]\"; o_tag = f\"[E2]{o_word}[/E2]\"\n",
        "\n",
        "    tmp = repl_first(sentence, s_word, s_tag)\n",
        "    tmp = repl_first(tmp, o_word, o_tag)\n",
        "    return tmp\n",
        "def tokenized_dataset(df, tokenizer, *,\n",
        "                      inline_markers=True, marker_variant=\"typed\", use_unk=True, max_len=256, use_erpe=False):\n",
        "    enc_inputs = []\n",
        "    for _, r in df.iterrows():\n",
        "        s = ast.literal_eval(r[\"subject_entity\"]) if isinstance(r[\"subject_entity\"], str) else r[\"subject_entity\"]\n",
        "        o = ast.literal_eval(r[\"object_entity\"]) if isinstance(r[\"object_entity\"], str) else r[\"object_entity\"]\n",
        "\n",
        "        if inline_markers:\n",
        "            text = _inline_mark(\n",
        "                r[\"sentence\"],\n",
        "                s.get(\"word\") if s else r[\"subj_word\"],\n",
        "                o.get(\"word\") if o else r[\"obj_word\"],\n",
        "                (s or {}).get(\"type\"), (o or {}).get(\"type\"),\n",
        "                use_type=(marker_variant == \"typed\"), use_unk=use_unk\n",
        "            )\n",
        "            enc_inputs.append(text)\n",
        "        else:\n",
        "            # Îëê Í∞úÏùò separate sequenceÎ°ú Íµ¨ÏÑ±\n",
        "            if marker_variant == \"typed\":\n",
        "                span = f\"[E1-{(s or {}).get('type','UNK')}]{(s or {}).get('word','<SUBJ>')}[/E1] \" \\\n",
        "                       f\"[E2-{(o or {}).get('type','UNK')}]{(o or {}).get('word','<OBJ>')}[/E2]\"\n",
        "            else:\n",
        "                span = f\"[E1]{(s or {}).get('word','<SUBJ>')}[/E1] [E2]{(o or {}).get('word','<OBJ>')}[/E2]\"\n",
        "            enc_inputs.append((span, r[\"sentence\"]))\n",
        "\n",
        "    # üîπ Î∞©Ïñ¥ ÏΩîÎìú: inline_markers Ïó¨Î∂ÄÏóê Îî∞Îùº tokenizer ÏûÖÎ†• Î∞©Ïãù Í≤∞Ï†ï\n",
        "    if inline_markers:\n",
        "        if enc_inputs and isinstance(enc_inputs[0], tuple):\n",
        "            raise ValueError(\"[tokenized_dataset] inline_markers=TrueÏù∏Îç∞ tuple ÌòïÏãùÏù¥ Í∞êÏßÄÎê®.\")\n",
        "        enc = tokenizer(\n",
        "            enc_inputs,\n",
        "            return_tensors=\"pt\",\n",
        "            padding=True,\n",
        "            truncation=True,\n",
        "            max_length=max_len,\n",
        "            add_special_tokens=True\n",
        "        )\n",
        "    else:\n",
        "        if not enc_inputs or not isinstance(enc_inputs[0], tuple):\n",
        "            raise ValueError(\"[tokenized_dataset] inline_markers=FalseÏù∏Îç∞ tuple ÌòïÏãùÏù¥ ÏïÑÎãò.\")\n",
        "        a, b = zip(*enc_inputs)\n",
        "        enc = tokenizer(\n",
        "            list(a), list(b),\n",
        "            return_tensors=\"pt\",\n",
        "            padding=True,\n",
        "            truncation=True,\n",
        "            max_length=max_len,\n",
        "            add_special_tokens=True\n",
        "        )\n",
        "\n",
        "    # ERPE Ï∂îÍ∞Ä Ï≤òÎ¶¨\n",
        "    if use_erpe:\n",
        "        e1_id = tokenizer.convert_tokens_to_ids(\"[E1]\")\n",
        "        e2_id = tokenizer.convert_tokens_to_ids(\"[E2]\")\n",
        "\n",
        "        def relpos(ids, mark_id, clip=128):\n",
        "            pos = (ids == mark_id).nonzero(as_tuple=True)[0]\n",
        "            m = int(pos[0]) if len(pos) else 0\n",
        "            ar = torch.arange(ids.size(0)) - m\n",
        "            ar.clamp_(-clip, clip).add_(clip)\n",
        "            return ar\n",
        "\n",
        "        input_ids = enc[\"input_ids\"]\n",
        "        enc[\"e1_relpos\"] = torch.stack([relpos(row, e1_id) for row in input_ids])\n",
        "        enc[\"e2_relpos\"] = torch.stack([relpos(row, e2_id) for row in input_ids])\n",
        "\n",
        "    enc.pop(\"token_type_ids\", None)\n",
        "    return enc\n"
      ],
      "metadata": {
        "id": "a4-03JvoFUEo"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# model_builders.py\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from transformers import AutoModel, AutoConfig\n",
        "\n",
        "class REMarkerHead(nn.Module):\n",
        "    def __init__(self, base_model, hidden_size, num_labels, use_cls=False, dropout=0.1, e1_id=None, e2_id=None):\n",
        "        super().__init__()\n",
        "        self.backbone = base_model\n",
        "        self.use_cls = use_cls\n",
        "        self.e1_id = e1_id\n",
        "        self.e2_id = e2_id\n",
        "        in_dim = hidden_size * (3 if use_cls else 2)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.classifier = nn.Linear(in_dim, num_labels)\n",
        "\n",
        "    @staticmethod\n",
        "    def _pick_first(mask, H):\n",
        "        idx = mask.float().argmax(dim=1)\n",
        "        return H[torch.arange(H.size(0), device=H.device), idx]\n",
        "\n",
        "    def forward(self, input_ids=None, attention_mask=None, token_type_ids=None, **kw):\n",
        "        out = self.backbone(input_ids=input_ids, attention_mask=attention_mask, return_dict=True)\n",
        "        H = out.last_hidden_state\n",
        "        e1_mask = (input_ids == self.e1_id); e2_mask = (input_ids == self.e2_id)\n",
        "        h1 = self._pick_first(e1_mask, H); h2 = self._pick_first(e2_mask, H)\n",
        "        feats = [h1, h2]\n",
        "        if self.use_cls: feats.append(H[:,0,:])\n",
        "        x = self.dropout(torch.cat(feats, dim=-1))\n",
        "        logits = self.classifier(x)\n",
        "        return {\"logits\": logits}\n",
        "\n",
        "class REMarkerHeadERPE(REMarkerHead):\n",
        "    def __init__(self, base_model, hidden_size, num_labels, erpe_dim=32, rel_vocab=257, **kw):\n",
        "        super().__init__(base_model, hidden_size, num_labels, **kw)\n",
        "        self.e1_pos_emb = nn.Embedding(rel_vocab, erpe_dim)\n",
        "        self.e2_pos_emb = nn.Embedding(rel_vocab, erpe_dim)\n",
        "        self.proj = nn.Linear(hidden_size + 2*erpe_dim, hidden_size)\n",
        "\n",
        "    def forward(self, input_ids=None, attention_mask=None, e1_relpos=None, e2_relpos=None, **kw):\n",
        "        out = self.backbone(input_ids=input_ids, attention_mask=attention_mask, return_dict=True)\n",
        "        H = out.last_hidden_state\n",
        "        P = torch.cat([self.e1_pos_emb(e1_relpos), self.e2_pos_emb(e2_relpos)], dim=-1)\n",
        "        H = self.proj(torch.cat([H, P], dim=-1))\n",
        "        e1_mask = (input_ids == self.e1_id); e2_mask = (input_ids == self.e2_id)\n",
        "        h1 = self._pick_first(e1_mask, H); h2 = self._pick_first(e2_mask, H)\n",
        "        x = self.dropout(torch.cat([h1, h2], dim=-1))\n",
        "        logits = self.classifier(x)\n",
        "        return {\"logits\": logits}\n",
        "\n",
        "def build_model(model_name: str, num_labels: int, tokenizer, *, use_marker_head=True, use_erpe=False, erpe_dim=32):\n",
        "    cfg = AutoConfig.from_pretrained(model_name, num_labels=num_labels)\n",
        "    base = AutoModel.from_pretrained(model_name, config=cfg)\n",
        "    # special tokens resizeÎäî Î∞îÍπ•ÏóêÏÑú Ïù¥ÎØ∏ Ï≤òÎ¶¨ÌñàÎã§Í≥† Í∞ÄÏ†ï\n",
        "\n",
        "    if not use_marker_head:\n",
        "        from transformers import AutoModelForSequenceClassification\n",
        "        return AutoModelForSequenceClassification.from_pretrained(model_name, config=cfg)\n",
        "\n",
        "    e1_id = tokenizer.convert_tokens_to_ids(\"[E1]\")\n",
        "    e2_id = tokenizer.convert_tokens_to_ids(\"[E2]\")\n",
        "    if use_erpe:\n",
        "        return REMarkerHeadERPE(base_model=base, hidden_size=cfg.hidden_size, num_labels=num_labels,\n",
        "                                erpe_dim=erpe_dim, e1_id=e1_id, e2_id=e2_id)\n",
        "    else:\n",
        "        return REMarkerHead(base_model=base, hidden_size=cfg.hidden_size, num_labels=num_labels,\n",
        "                            use_cls=False, e1_id=e1_id, e2_id=e2_id)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "REkkJKR5FXNC"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# trainer_plus.py\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader, WeightedRandomSampler\n",
        "from transformers import Trainer\n",
        "\n",
        "def build_llrd_param_groups(model, base_lr=2e-5, lr_decay=0.95, wd=0.01):\n",
        "    groups = []\n",
        "\n",
        "    def collect(names):\n",
        "        return [p for n,p in model.named_parameters() if any(k in n for k in names) and p.requires_grad]\n",
        "\n",
        "    # üîß ÏûÑÎ≤†Îî©ÏùÑ word / position / layer-normÏúºÎ°ú Î∂ÑÎ¶¨\n",
        "    emb_word = collect([\"embeddings.word_embeddings\"])\n",
        "    emb_pos  = collect([\"embeddings.position_embeddings\"])\n",
        "    emb_ln   = collect([\"embeddings.LayerNorm\"])\n",
        "\n",
        "    if emb_word: groups.append({\"params\": emb_word, \"lr\": base_lr*(lr_decay**12), \"weight_decay\": wd})\n",
        "    if emb_pos:  groups.append({\"params\": emb_pos,  \"lr\": base_lr*(lr_decay**12), \"weight_decay\": 0.0})  # Î≥¥ÌÜµ decay=0\n",
        "    if emb_ln:   groups.append({\"params\": emb_ln,   \"lr\": base_lr*(lr_decay**12), \"weight_decay\": 0.0})\n",
        "\n",
        "    for i in range(12):\n",
        "        groups.append({\"params\": collect([f\"encoder.layer.{i}\"]), \"lr\": base_lr*(lr_decay**(11-i)), \"weight_decay\": wd})\n",
        "\n",
        "    # pooler / classifier\n",
        "    groups.append({\"params\": collect([\"pooler\", \"classifier\"]), \"lr\": base_lr, \"weight_decay\": wd})\n",
        "    return groups\n",
        "\n",
        "class TrainerPlus(Trainer):\n",
        "    def __init__(self, *args,\n",
        "                 class_weights=None,\n",
        "                 use_focal=False, focal_gamma=2.0,\n",
        "                 rdrop_alpha=0.0,\n",
        "                 use_llrd=False, llrd_decay=0.95,\n",
        "                 optimizer_betas=(0.9, 0.999),\n",
        "                 wd=0.01,\n",
        "                 use_fgm=False, fgm_eps=1e-3,\n",
        "                 **kwargs):\n",
        "        super().__init__(*args, **kwargs)\n",
        "        self.class_weights = class_weights\n",
        "        self.use_focal = use_focal\n",
        "        self.focal_gamma = focal_gamma\n",
        "        self.rdrop_alpha = rdrop_alpha\n",
        "        self.use_llrd = use_llrd\n",
        "        self.llrd_decay = llrd_decay\n",
        "        self.optimizer_betas = optimizer_betas\n",
        "        self._wd = wd\n",
        "        self.use_fgm = use_fgm\n",
        "        self.fgm_eps = fgm_eps\n",
        "        self._fgm_backup = {}\n",
        "\n",
        "    # ---- losses ----\n",
        "    # Fix device handling in TrainerPlus\n",
        "    def _ce(self, logits, labels):\n",
        "        weights = self.class_weights\n",
        "        if weights is not None:\n",
        "            weights = weights.to(logits.device)  # Ensure same device\n",
        "        return F.cross_entropy(logits, labels, weight=weights)\n",
        "\n",
        "    def _focal(self, logits, labels):\n",
        "        weights = self.class_weights\n",
        "        if weights is not None:\n",
        "            weights = weights.to(logits.device)  # Ensure same device\n",
        "        ce = F.cross_entropy(logits, labels, reduction=\"none\", weight=weights)\n",
        "        p = logits.softmax(dim=-1)[torch.arange(len(labels), device=logits.device), labels]\n",
        "        return ((1 - p) ** self.focal_gamma * ce).mean()\n",
        "    def compute_loss(\n",
        "        self,\n",
        "        model,\n",
        "        inputs,\n",
        "        return_outputs: bool = False,\n",
        "        num_items_in_batch=None,   # ‚úÖ ÏµúÏã† HFÍ∞Ä ÎÑòÍ∏∞Îäî Ïù∏Ïûê ÏàòÏö©\n",
        "        **kwargs,                  # ‚úÖ ÏïûÏúºÎ°úÏùò ÌôïÏû• ÎåÄÎπÑ\n",
        "    ):\n",
        "        labels = inputs[\"labels\"]\n",
        "        out1 = model(**inputs)\n",
        "        logits1 = out1[\"logits\"]\n",
        "\n",
        "        base = self._focal(logits1, labels) if self.use_focal else self._ce(logits1, labels)\n",
        "\n",
        "        if self.rdrop_alpha > 0 and model.training:\n",
        "            out2 = model(**inputs)\n",
        "            logits2 = out2[\"logits\"]\n",
        "            base2 = self._focal(logits2, labels) if self.use_focal else self._ce(logits2, labels)\n",
        "            base = 0.5 * (base + base2)\n",
        "            p1 = logits1.log_softmax(dim=-1); p2 = logits2.log_softmax(dim=-1)\n",
        "            kl = F.kl_div(p1, p2.exp(), reduction=\"batchmean\") + F.kl_div(p2, p1.exp(), reduction=\"batchmean\")\n",
        "            loss = base + 0.5 * self.rdrop_alpha * kl\n",
        "            return (loss, out1) if return_outputs else loss\n",
        "\n",
        "        return (base, out1) if return_outputs else base\n",
        "\n",
        "    # ---- FGM by overriding training_step (proper sequence) ----\n",
        "    def _fgm_attack(self, emb_name=\"embeddings.word_embeddings\"):\n",
        "        for n, p in self.model.named_parameters():\n",
        "            if p.requires_grad and emb_name in n and p.grad is not None:\n",
        "                self._fgm_backup[n] = p.data.clone()\n",
        "                g = p.grad / (p.grad.norm() + 1e-12)\n",
        "                p.data.add_(self.fgm_eps * g)\n",
        "\n",
        "    def _fgm_restore(self):\n",
        "        for n, p in self.model.named_parameters():\n",
        "            if n in self._fgm_backup:\n",
        "                p.data = self._fgm_backup[n]\n",
        "        self._fgm_backup.clear()\n",
        "\n",
        "\n",
        "    def training_step(self, model, inputs, num_items_in_batch=None):\n",
        "        # 1) HF Í∏∞Î≥∏ training_step Î®ºÏ†Ä Ìò∏Ï∂ú ‚Üí AMP/Scaler/accumulation Î™®Îëê ÏïàÏ†Ñ Ï≤òÎ¶¨\n",
        "        base_loss_detached = super().training_step(model, inputs, num_items_in_batch)\n",
        "\n",
        "        # 2) FGM ÏûàÏúºÎ©¥ Îëê Î≤àÏß∏ forward/backward (Ïä§ÏºÄÏùºÎü¨ Í∑úÏπô Í∑∏ÎåÄÎ°ú ÎßûÏ∂∞Ï§å)\n",
        "        if self.use_fgm:\n",
        "            self._fgm_attack()\n",
        "            with self.autocast_smart_context_manager():\n",
        "                adv_loss = self.compute_loss(model, self._prepare_inputs(inputs))\n",
        "            if self.args.n_gpu > 1:\n",
        "                adv_loss = adv_loss.mean()\n",
        "            adv_loss = adv_loss / self.args.gradient_accumulation_steps\n",
        "\n",
        "            # HFÍ∞Ä ÏÑ§Ï†ïÌïú Ïä§ÏºÄÏùºÎü¨ ÌîåÎûòÍ∑∏Î•º Í∑∏ÎåÄÎ°ú ÏÇ¨Ïö©\n",
        "            use_scaler = getattr(self, \"do_grad_scaling\", False) and getattr(self, \"scaler\", None) is not None\n",
        "            if use_scaler:\n",
        "                self.scaler.scale(adv_loss).backward()\n",
        "            else:\n",
        "                adv_loss.backward()\n",
        "            self._fgm_restore()\n",
        "\n",
        "        return base_loss_detached\n",
        "\n",
        "\n",
        "    # ---- optimizer with LLRD ----\n",
        "    def create_optimizer(self):\n",
        "        if self.optimizer is not None:\n",
        "            return self.optimizer\n",
        "        lr = self.args.learning_rate; wd = self._wd; betas = self.optimizer_betas\n",
        "        no_decay = [\"bias\", \"LayerNorm.weight\", \"LayerNorm.bias\"]\n",
        "        if self.use_llrd:\n",
        "            base_groups = build_llrd_param_groups(self.model, base_lr=lr, lr_decay=self.llrd_decay, wd=wd)\n",
        "            groups = []\n",
        "            for g in base_groups:\n",
        "                dec, nde = [], []\n",
        "                for n, p in self.model.named_parameters():\n",
        "                    if p not in g[\"params\"] or not p.requires_grad: continue\n",
        "                    (nde if any(nd in n for nd in no_decay) else dec).append(p)\n",
        "                if dec: groups.append({\"params\": dec, \"lr\": g[\"lr\"], \"weight_decay\": wd})\n",
        "                if nde: groups.append({\"params\": nde, \"lr\": g[\"lr\"], \"weight_decay\": 0.0})\n",
        "            param_groups = groups\n",
        "        else:\n",
        "            dec, nde = [], []\n",
        "            for n,p in self.model.named_parameters():\n",
        "                if not p.requires_grad: continue\n",
        "                (nde if any(nd in n for nd in no_decay) else dec).append(p)\n",
        "            param_groups = [\n",
        "                {\"params\": dec, \"weight_decay\": wd, \"lr\": lr},\n",
        "                {\"params\": nde, \"weight_decay\": 0.0, \"lr\": lr},\n",
        "            ]\n",
        "        self.optimizer = torch.optim.AdamW(param_groups, lr=lr, betas=betas)\n",
        "        return self.optimizer\n",
        "\n",
        "    # ---- weighted sampler (for hard-neg callback) ----\n",
        "    def get_train_dataloader(self):\n",
        "        if hasattr(self.train_dataset, \"weights\") and self.train_dataset.weights is not None:\n",
        "            sampler = WeightedRandomSampler(self.train_dataset.weights, num_samples=len(self.train_dataset), replacement=True)\n",
        "            return DataLoader(self.train_dataset, batch_size=self.args.train_batch_size,\n",
        "                              sampler=sampler, collate_fn=self.data_collator)\n",
        "        return super().get_train_dataloader()\n",
        "\n"
      ],
      "metadata": {
        "id": "icN9kyWKFYkq"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# hardneg_callback.py\n",
        "import torch, numpy as np\n",
        "from torch.utils.data import DataLoader\n",
        "from transformers import TrainerCallback\n",
        "\n",
        "class HardNegSampler(TrainerCallback):\n",
        "    def __init__(self, no_rel_id=0, tau=0.55, boost=2.0):\n",
        "        self.no_rel_id = no_rel_id\n",
        "        self.tau = tau\n",
        "        self.boost = boost\n",
        "\n",
        "    def on_epoch_end(self, args, state, control, **kw):\n",
        "        tr = kw[\"trainer\"]\n",
        "        ds = tr.train_dataset\n",
        "        if not hasattr(ds, \"weights\"):\n",
        "            ds.weights = np.ones(len(ds), dtype=np.float32)\n",
        "\n",
        "        dl = DataLoader(ds, batch_size=args.per_device_eval_batch_size)\n",
        "        probs_all, labels_all = [], []\n",
        "        tr.model.eval()\n",
        "        with torch.no_grad():\n",
        "            for batch in dl:\n",
        "                batch = {k: v.to(tr.model.device) if isinstance(v, torch.Tensor) else v for k, v in batch.items()}\n",
        "                logits = tr.model(**batch)[\"logits\"]\n",
        "                probs_all.append(logits.softmax(-1).cpu())\n",
        "                labels_all.append(batch[\"labels\"].cpu())\n",
        "        probs = torch.cat(probs_all).numpy()\n",
        "        labels = torch.cat(labels_all).numpy()\n",
        "        p_nr = probs[:, self.no_rel_id]\n",
        "        hard = (labels == self.no_rel_id) & (p_nr < self.tau)\n",
        "\n",
        "        w = ds.weights.astype(np.float32)\n",
        "        w[hard] *= self.boost\n",
        "        ds.weights = w\n",
        "        tr.train_dataloader = None  # Ïû¨ÏÉùÏÑ± Ìä∏Î¶¨Í±∞\n",
        "\n"
      ],
      "metadata": {
        "id": "MR9Ks7zGFZy1"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train_re.py\n",
        "import os, numpy as np, torch\n",
        "from typing import List, Optional\n",
        "from dataclasses import replace\n",
        "from sklearn.model_selection import train_test_split\n",
        "from transformers import AutoTokenizer, TrainingArguments, EarlyStoppingCallback\n",
        "import sklearn\n",
        "\n",
        "# from parts_config import TrainConfig, DEFAULT_LABEL_LIST\n",
        "# from data_plus import RE_Dataset, load_data, tokenized_dataset\n",
        "# from model_builders import build_model\n",
        "# from trainer_plus import TrainerPlus\n",
        "\n",
        "def train_re(\n",
        "    train_csv: str,\n",
        "    dev_csv: Optional[str],\n",
        "    label_list: List[str] = DEFAULT_LABEL_LIST,\n",
        "    cfg: TrainConfig = TrainConfig(),\n",
        "    save_best_to: str = \"./best_model\",\n",
        "    callbacks=None,\n",
        "):\n",
        "    torch.manual_seed(cfg.seed); np.random.seed(cfg.seed)\n",
        "\n",
        "    tokenizer = AutoTokenizer.from_pretrained(cfg.model_name, use_fast=True)\n",
        "    special_tokens = [\"[E1]\",\"[/E1]\",\"[E2]\",\"[/E2]\"]\n",
        "    if cfg.marker_variant == \"typed\":\n",
        "        special_tokens += [\"[E1-PER]\",\"[E2-PER]\",\"[E1-ORG]\",\"[E2-ORG]\",\"[E1-LOC]\",\"[E2-LOC]\",\"[E1-UNK]\",\"[E2-UNK]\"]\n",
        "    added = tokenizer.add_special_tokens({\"additional_special_tokens\": special_tokens})\n",
        "\n",
        "    model = build_model(\n",
        "        cfg.model_name,\n",
        "        num_labels=len(label_list),\n",
        "        tokenizer=tokenizer,\n",
        "        use_marker_head=cfg.use_marker_head,\n",
        "        use_erpe=cfg.use_erpe,\n",
        "        erpe_dim=cfg.erpe_dim\n",
        "    )\n",
        "\n",
        "    if added > 0:\n",
        "        if hasattr(model, \"resize_token_embeddings\"):\n",
        "            model.resize_token_embeddings(len(tokenizer), mean_resizing=False)\n",
        "        elif hasattr(model, \"backbone\") and hasattr(model.backbone, \"resize_token_embeddings\"):\n",
        "            model.backbone.resize_token_embeddings(len(tokenizer), mean_resizing=False)\n",
        "\n",
        "    full_df = load_data(train_csv)\n",
        "    if dev_csv:\n",
        "        train_df, dev_df = full_df, load_data(dev_csv)\n",
        "    else:\n",
        "        train_df, dev_df = train_test_split(full_df, test_size=0.1, random_state=cfg.seed, stratify=full_df[\"label\"])\n",
        "\n",
        "    label_map = {v: i for i, v in enumerate(label_list)}\n",
        "    y_tr = [label_map[v] for v in train_df[\"label\"].values]\n",
        "    y_dv = [label_map[v] for v in dev_df[\"label\"].values]\n",
        "\n",
        "    tok_tr = tokenized_dataset(train_df, tokenizer,\n",
        "                               inline_markers=cfg.inline_markers, marker_variant=cfg.marker_variant,\n",
        "                               max_len=cfg.max_length, use_erpe=cfg.use_erpe)\n",
        "    tok_dv = tokenized_dataset(dev_df, tokenizer,\n",
        "                               inline_markers=cfg.inline_markers, marker_variant=cfg.marker_variant,\n",
        "                               max_len=cfg.max_length, use_erpe=cfg.use_erpe)\n",
        "\n",
        "    ds_tr = RE_Dataset(tok_tr, y_tr)\n",
        "    ds_dv = RE_Dataset(tok_dv, y_dv)\n",
        "\n",
        "    # class weights\n",
        "    # class weights\n",
        "    class_weights = None\n",
        "    if cfg.use_cb_loss:\n",
        "        beta = 0.999\n",
        "        counts = np.bincount(y_tr, minlength=len(label_list))\n",
        "        eff_num = 1.0 - np.power(beta, counts)\n",
        "        cbw = (1.0 - beta) / np.clip(eff_num, 1e-6, None)\n",
        "        cbw = cbw / cbw.mean()\n",
        "        class_weights = torch.tensor(cbw, dtype=torch.float32)  # Remove device specification\n",
        "    elif cfg.use_class_weight:\n",
        "        counts = np.bincount(y_tr, minlength=len(label_list))\n",
        "        inv = 1.0 / np.clip(counts, 1, None)\n",
        "        w = inv / inv.mean()\n",
        "        class_weights = torch.tensor(w, dtype=torch.float32)  # Remove device specification\n",
        "\n",
        "    # Fix: Move this to the correct indentation level (same as the class_weights section above)\n",
        "\n",
        "    args = TrainingArguments(\n",
        "        output_dir=cfg.output_dir,\n",
        "        save_total_limit=cfg.save_total_limit,\n",
        "\n",
        "        eval_strategy=\"steps\",   # ‚úÖ Ï≤†Ïûê Ï†ïÌôï\n",
        "        save_strategy=\"steps\",\n",
        "        eval_steps=cfg.eval_steps,\n",
        "        save_steps=cfg.eval_steps,\n",
        "\n",
        "        load_best_model_at_end=True,\n",
        "        metric_for_best_model=\"micro_f1\",  # ‚úÖ compute_metrics Î¶¨ÌÑ¥ ÌÇ§ÏôÄ ÎèôÏùº (eval_ Î∂ôÏù¥ÏßÄ ÏïäÏùå)\n",
        "        greater_is_better=True,\n",
        "\n",
        "        label_names=[\"labels\"],\n",
        "\n",
        "        num_train_epochs=cfg.num_train_epochs,\n",
        "        learning_rate=cfg.learning_rate,\n",
        "        per_device_train_batch_size=cfg.per_device_train_batch_size,\n",
        "        per_device_eval_batch_size=cfg.per_device_eval_batch_size,\n",
        "        weight_decay=cfg.weight_decay,\n",
        "\n",
        "        logging_strategy=\"steps\",\n",
        "        logging_steps=cfg.logging_steps,\n",
        "\n",
        "        fp16=cfg.fp16 and torch.cuda.is_available(),\n",
        "        seed=cfg.seed,\n",
        "        remove_unused_columns=False,\n",
        "        dataloader_pin_memory=torch.cuda.is_available(),\n",
        "        report_to=\"none\",\n",
        "        label_smoothing_factor=cfg.label_smoothing,\n",
        "        lr_scheduler_type=cfg.lr_scheduler_type,\n",
        "        warmup_ratio=cfg.warmup_ratio,\n",
        "    )\n",
        "\n",
        "    def micro_f1_wo_no_relation(preds, labels, label_list, no_rel=\"no_relation\"):\n",
        "        no_rel_idx = label_list.index(no_rel)\n",
        "        use_labels = [i for i in range(len(label_list)) if i != no_rel_idx]\n",
        "        return sklearn.metrics.f1_score(labels, preds, average=\"micro\", labels=use_labels) * 100.0\n",
        "\n",
        "    def auprc_all(probs, labels, num_labels):\n",
        "        labels_oh = np.eye(num_labels)[labels]\n",
        "        score = []\n",
        "        for c in range(num_labels):\n",
        "            t = labels_oh[:, c]; p = probs[:, c]\n",
        "            prec, rec, _ = sklearn.metrics.precision_recall_curve(t, p)\n",
        "            score.append(sklearn.metrics.auc(rec, prec))\n",
        "        return float(np.mean(score) * 100.0)\n",
        "\n",
        "\n",
        "    def compute_metrics(eval_pred):\n",
        "        try:\n",
        "            # HFÍ∞Ä EvalPredictionÏùÑ Ï£ºÎäî Î≤ÑÏ†Ñ/ÏºÄÏù¥Ïä§ÎèÑ ÏûàÍ≥† tupleÎèÑ ÏûàÏñ¥ÏÑú Î™®Îëê ÎåÄÏùë\n",
        "            if hasattr(eval_pred, \"predictions\"):\n",
        "                logits, labels = eval_pred.predictions, eval_pred.label_ids\n",
        "            else:\n",
        "                logits, labels = eval_pred\n",
        "\n",
        "            import numpy as np\n",
        "            if isinstance(logits, tuple): logits = logits[0]\n",
        "            logits = np.asarray(logits)\n",
        "            labels = np.asarray(labels)\n",
        "\n",
        "            preds = logits.argmax(-1)\n",
        "\n",
        "            # ÌôïÎ•† Í≥ÑÏÇ∞: torch ÏóÜÏù¥ numpyÎ°ú ÏïàÏ†ÑÌïòÍ≤å\n",
        "            # (Ïò§Î≤ÑÌîåÎ°úÏö∞ Î∞©ÏßÄÏö© ÏïàÏ†ïÌôî softmax)\n",
        "            logits_max = logits.max(axis=1, keepdims=True)\n",
        "            exps = np.exp(logits - logits_max)\n",
        "            probs = exps / exps.sum(axis=1, keepdims=True)\n",
        "\n",
        "            from sklearn.metrics import f1_score, accuracy_score, precision_recall_curve, auc\n",
        "            no_rel_idx = DEFAULT_LABEL_LIST.index(\"no_relation\")\n",
        "            use_labels = [i for i in range(len(DEFAULT_LABEL_LIST)) if i != no_rel_idx]\n",
        "\n",
        "            micro_f1 = f1_score(labels, preds, average=\"micro\", labels=use_labels) * 100.0\n",
        "\n",
        "            # AUPRC Í≥ÑÏÇ∞ Ï§ë ÌÅ¥ÎûòÏä§Í∞Ä ÎπÑÏñ¥ ÏûàÏùÑ Ïàò ÏûàÏúºÎãà tryÎ°ú Î≥¥Ìò∏\n",
        "            try:\n",
        "                labels_oh = np.eye(logits.shape[1], dtype=int)[labels]\n",
        "                auprs = []\n",
        "                for c in range(logits.shape[1]):\n",
        "                    t = labels_oh[:, c]; p = probs[:, c]\n",
        "                    # precision_recall_curveÎäî Î∞òÌôò (prec, rec, thr)\n",
        "                    prec, rec, _ = precision_recall_curve(t, p)\n",
        "                    # auc(x, y)ÏóêÏÑú x=rec, y=prec\n",
        "                    auprs.append(auc(rec, prec))\n",
        "                auprc = float(np.mean(auprs) * 100.0)\n",
        "            except Exception:\n",
        "                auprc = float(\"nan\")\n",
        "\n",
        "            return {\n",
        "                \"micro_f1\": float(micro_f1),\n",
        "                \"auprc\": float(auprc),\n",
        "                \"accuracy\": float(accuracy_score(labels, preds) * 100.0),\n",
        "            }\n",
        "        except Exception as e:\n",
        "            # Ïñ¥Îñ§ Í≤ΩÏö∞ÏóêÎèÑ Îπà dictÍ∞Ä ÎÑòÏñ¥Í∞ÄÎ©¥ Ïïà ÎêòÎØÄÎ°ú ÏµúÏÜå Î©îÌä∏Î¶≠ Î∞òÌôò\n",
        "            return {\n",
        "                \"micro_f1\": 0.0,\n",
        "                \"auprc\": 0.0,\n",
        "                \"accuracy\": 0.0,\n",
        "            }\n",
        "\n",
        "\n",
        "    # default_cbs = [EarlyStoppingCallback(early_stopping_patience=5)]\n",
        "    # use_callbacks = default_cbs + (callbacks or [])\n",
        "\n",
        "    trainer = TrainerPlus(\n",
        "        model=model, args=args,\n",
        "        train_dataset=ds_tr, eval_dataset=ds_dv,\n",
        "        compute_metrics=compute_metrics, processing_class=tokenizer,\n",
        "        class_weights=class_weights,\n",
        "        use_focal=cfg.use_focal, focal_gamma=cfg.focal_gamma,\n",
        "        rdrop_alpha=cfg.rdrop_alpha,\n",
        "        use_llrd=cfg.use_llrd, llrd_decay=cfg.llrd_decay,\n",
        "        wd=cfg.weight_decay,\n",
        "        use_fgm=cfg.use_fgm, fgm_eps=cfg.fgm_eps,\n",
        "        callbacks=[EarlyStoppingCallback(early_stopping_patience=cfg.es_patience)]\n",
        "    )\n",
        "\n",
        "    trainer.train()\n",
        "    os.makedirs(save_best_to, exist_ok=True)\n",
        "    trainer.save_model(save_best_to)\n",
        "    if trainer.tokenizer: trainer.tokenizer.save_pretrained(save_best_to)\n",
        "    return trainer\n"
      ],
      "metadata": {
        "id": "oW1svTMnFjyJ"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# grid_plus.py\n",
        "import os, time, gc, shutil, inspect\n",
        "from typing import Optional, List, Dict, Any\n",
        "from itertools import product\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "from transformers import TrainerCallback, EarlyStoppingCallback\n",
        "\n",
        "# from parts_config import TrainConfig, DEFAULT_LABEL_LIST\n",
        "# from train_re import train_re\n",
        "# from hardneg_callback import HardNegSampler\n",
        "\n",
        "class ConsoleLogger(TrainerCallback):\n",
        "    def on_train_begin(self, args, state, control, **kwargs):\n",
        "        print(f\"[train] start ‚Üí out={args.output_dir} | lr={args.learning_rate} | bsz={args.per_device_train_batch_size} | epochs={args.num_train_epochs}\")\n",
        "\n",
        "    def on_log(self, args, state, control, logs=None, **kwargs):\n",
        "        if not state.is_world_process_zero or not logs: return\n",
        "        keys = [\"loss\",\"learning_rate\",\"epoch\"]\n",
        "        msg = \" | \".join([f\"{k}={logs[k]:.5f}\" for k in keys if k in logs])\n",
        "        for k in [\"micro f1 score\",\"auprc\",\"accuracy\"]:\n",
        "            if k in logs: msg += f\" | {k}={logs[k]:.3f}\"\n",
        "        print(f\"[step {state.global_step}] {msg}\")\n",
        "\n",
        "    def on_train_end(self, args, state, control, **kwargs):\n",
        "        print(f\"[train] end. best={state.best_model_checkpoint}\")\n",
        "\n",
        "def run_grid_plus(\n",
        "    train_csv: str,\n",
        "    dev_csv: Optional[str],\n",
        "    models: List[str],\n",
        "    hp_space: Dict[str, list],\n",
        "    base_out: str = \"./grid_runs_plus\",\n",
        "    seed_list: List[int] = (42,),\n",
        "    label_list: List[str] = None,\n",
        "    extra_callbacks: Optional[List[TrainerCallback]] = None,\n",
        ") -> pd.DataFrame:\n",
        "    if label_list is None:\n",
        "        label_list = DEFAULT_LABEL_LIST\n",
        "    os.makedirs(base_out, exist_ok=True)\n",
        "\n",
        "    keys, values = zip(*hp_space.items())\n",
        "    combos = list(product(*values))\n",
        "\n",
        "    results = []\n",
        "    total = len(models) * len(seed_list) * len(combos)\n",
        "    idx = 0\n",
        "\n",
        "    for model_name in models:\n",
        "        for seed in seed_list:\n",
        "            for vals in combos:\n",
        "                idx += 1\n",
        "                opt = dict(zip(keys, vals))\n",
        "\n",
        "                run_name = (\n",
        "                    f\"{model_name.replace('/','_')}\"\n",
        "                    f\"_lr{opt['lr']}_ep{opt['epochs']}_bs{opt['train_bsz']}\"\n",
        "                    f\"_ml{opt['max_len']}_mk{opt['marker_variant']}\"\n",
        "                    f\"_inline{int(opt['inline_markers'])}\"\n",
        "                    f\"_mh{int(opt['use_marker_head'])}_erpe{int(opt['use_erpe'])}_ed{opt['erpe_dim']}\"\n",
        "                    f\"_fgm{int(opt['use_fgm'])}\"\n",
        "                    f\"_cb{int(opt['use_cb_loss'])}_cw{int(opt['use_class_weight'])}\"\n",
        "                    f\"_focal{int(opt['use_focal'])}_rd{opt['rdrop_alpha']}_llrd{int(opt['use_llrd'])}\"\n",
        "                    f\"_hn{int(opt['use_hardneg'])}_tau{opt['hardneg_tau']}_boost{opt['hardneg_boost']}\"\n",
        "                    f\"_seed{seed}\"\n",
        "                )\n",
        "                out_dir = os.path.join(base_out, run_name)\n",
        "                best_dir = os.path.join(out_dir, \"best\")\n",
        "\n",
        "                if torch.cuda.is_available(): torch.cuda.empty_cache()\n",
        "                gc.collect()\n",
        "\n",
        "                t0 = time.time()\n",
        "                row = {\"run\": run_name, \"model\": model_name, \"seed\": seed, **opt,\n",
        "                       \"output_dir\": out_dir, \"best_dir\": best_dir,\n",
        "                       \"micro_f1\": None, \"auprc\": None, \"accuracy\": None,\n",
        "                       \"micro_f1_tta\": None, \"best_ckpt\": None, \"seconds\": None, \"error\": None}\n",
        "\n",
        "                try:\n",
        "                    cfg = TrainConfig(\n",
        "                        model_name=model_name,\n",
        "                        output_dir=out_dir,\n",
        "                        num_train_epochs=opt[\"epochs\"],\n",
        "                        learning_rate=opt[\"lr\"],\n",
        "                        per_device_train_batch_size=opt[\"train_bsz\"],\n",
        "                        per_device_eval_batch_size=opt[\"train_bsz\"],\n",
        "                        warmup_ratio=opt[\"warmup_ratio\"],\n",
        "                        weight_decay=0.01,\n",
        "                        logging_steps=2000, save_steps=2000, eval_steps=2000,\n",
        "                        save_total_limit=2, load_best_model_at_end=True,\n",
        "                        seed=seed, max_length=opt[\"max_len\"], fp16=torch.cuda.is_available(),\n",
        "                        inline_markers=opt[\"inline_markers\"],\n",
        "                        marker_variant=opt[\"marker_variant\"],\n",
        "                        label_smoothing=opt[\"label_smoothing\"],\n",
        "                        lr_scheduler_type=opt[\"scheduler\"],\n",
        "                        use_class_weight=opt[\"use_class_weight\"],\n",
        "                        use_cb_loss=opt[\"use_cb_loss\"],\n",
        "                        use_focal=opt[\"use_focal\"], focal_gamma=opt[\"focal_gamma\"],\n",
        "                        rdrop_alpha=opt[\"rdrop_alpha\"],\n",
        "                        use_llrd=opt[\"use_llrd\"], llrd_decay=opt[\"llrd_decay\"],\n",
        "                        use_marker_head=opt[\"use_marker_head\"],\n",
        "                        use_erpe=opt[\"use_erpe\"], erpe_dim=opt[\"erpe_dim\"],\n",
        "                        use_fgm=opt[\"use_fgm\"], fgm_eps=opt[\"fgm_eps\"],\n",
        "                        use_hardneg=opt[\"use_hardneg\"],\n",
        "                        hardneg_tau=opt[\"hardneg_tau\"], hardneg_boost=opt[\"hardneg_boost\"],\n",
        "                    )\n",
        "\n",
        "                    cbs: List[TrainerCallback] = [ConsoleLogger(), EarlyStoppingCallback(early_stopping_patience=5)]\n",
        "                    if cfg.use_hardneg:\n",
        "                        cbs.append(HardNegSampler(no_rel_id=0, tau=cfg.hardneg_tau, boost=cfg.hardneg_boost))\n",
        "                    if extra_callbacks: cbs.extend(extra_callbacks)\n",
        "\n",
        "                    trainer = train_re(\n",
        "                        train_csv=train_csv, dev_csv=dev_csv,\n",
        "                        label_list=label_list, cfg=cfg, save_best_to=best_dir,\n",
        "                        callbacks=cbs\n",
        "                    )\n",
        "\n",
        "                    metrics = trainer.evaluate()\n",
        "                    row[\"micro_f1\"] = metrics.get(\"micro f1 score\")\n",
        "                    row[\"auprc\"] = metrics.get(\"auprc\")\n",
        "                    row[\"accuracy\"] = metrics.get(\"accuracy\")\n",
        "                    state = getattr(trainer, \"state\", None)\n",
        "                    row[\"best_ckpt\"] = getattr(state, \"best_model_checkpoint\", None)\n",
        "\n",
        "                    # Optional: TTA (MC Dropout)\n",
        "                    if opt.get(\"use_tta\", False):\n",
        "                        trainer.model.train()\n",
        "                        preds = []\n",
        "                        with torch.no_grad():\n",
        "                            for _ in range(int(opt.get(\"tta_n\", 4))):\n",
        "                                out = trainer.predict(trainer.eval_dataset)\n",
        "                                preds.append(out.predictions)\n",
        "                        tta_logits = np.mean(preds, axis=0)\n",
        "                        labels = trainer.predict(trainer.eval_dataset).label_ids\n",
        "                        from sklearn.metrics import f1_score\n",
        "                        no_rel = label_list.index(\"no_relation\")\n",
        "                        y_hat = tta_logits.argmax(-1)\n",
        "                        row[\"micro_f1_tta\"] = f1_score(labels, y_hat, average=\"micro\", labels=[i for i in range(len(label_list)) if i!=no_rel]) * 100.0\n",
        "\n",
        "                except Exception as e:\n",
        "                    row[\"error\"] = f\"{type(e).__name__}: {e}\"\n",
        "                finally:\n",
        "                    row[\"seconds\"] = round(time.time() - t0, 2)\n",
        "                    results.append(row)\n",
        "                    # Ï≤¥ÌÅ¨Ìè¨Ïù∏Ìä∏Îäî ÎÇ®Í∏∞Í≥†, Îü¨Îãù Î°úÍ∑∏ Ìè¥ÎçîÎßå Ï†ïÎ¶¨ÌïòÍ≥† Ïã∂ÏúºÎ©¥ ÏïÑÎûò Ï§Ñ Ï£ºÏÑù Ï≤òÎ¶¨\n",
        "                    shutil.rmtree(out_dir, ignore_errors=True)\n",
        "                    if torch.cuda.is_available(): torch.cuda.empty_cache()\n",
        "                    gc.collect()\n",
        "\n",
        "                print(f\"[{idx}/{total}] done: {row['run']} | microF1={row['micro_f1']} | err={row['error']}\")\n",
        "\n",
        "                df = pd.DataFrame(results)\n",
        "                print(df)\n",
        "                # .sort_values(by=[\"micro_f1\",\"auprc\",\"accuracy\"], ascending=False, na_position=\"last\")\n",
        "                df.to_csv(os.path.join(base_out, f\"{run_name}_grid_summary.csv\"), index=False, encoding=\"utf-8-sig\", method = 'a')\n",
        "    return df\n"
      ],
      "metadata": {
        "id": "cioBmmgqFmJ5"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# run.py\n",
        "# from grid_plus.py import run_grid_plus\n",
        "# from parts_config import DEFAULT_LABEL_LIST\n",
        "\n",
        "TRAIN_CSV = \"/content/drive/MyDrive/Colab Notebooks/upstage/dataset/train.csv\"\n",
        "DEV_CSV   = None  # ÏóÜÏúºÎ©¥ None\n",
        "\n",
        "MODELS = [\n",
        "    \"klue/roberta-base\",\n",
        "    # \"microsoft/deberta-v3-base\",\n",
        "    # \"klue/roberta-large\",\n",
        "]\n",
        "\n",
        "HP_SPACE = {\n",
        "    # Í∏∞Î≥∏ HP\n",
        "    \"lr\":              [2e-5],\n",
        "    \"epochs\":          [10],\n",
        "    \"train_bsz\":       [32],\n",
        "    \"max_len\":         [256],\n",
        "    \"scheduler\":       [\"cosine\"],\n",
        "    \"warmup_ratio\":    [0.05],\n",
        "    \"label_smoothing\": [0.1],\n",
        "\n",
        "    # ÌëúÌòÑ\n",
        "    \"marker_variant\":  [\"typed\"],\n",
        "    \"inline_markers\":  [True],\n",
        "\n",
        "    # ÏÜêÏã§/Ï†ïÍ∑úÌôî\n",
        "    \"use_class_weight\":[False],\n",
        "    \"use_cb_loss\":     [True],\n",
        "    \"use_focal\":       [False],\n",
        "    \"focal_gamma\":     [2.0],\n",
        "    \"rdrop_alpha\":     [0.0, 2.0],\n",
        "\n",
        "    # Íµ¨Ï°∞/Ìä∏Î¶≠\n",
        "    \"use_marker_head\": [True, False],\n",
        "    \"use_erpe\":        [False, True],\n",
        "    \"erpe_dim\":        [32],\n",
        "    \"use_fgm\":         [False, True],\n",
        "    \"fgm_eps\":         [1e-3],\n",
        "\n",
        "    # ÏµúÏ†ÅÌôî\n",
        "    \"use_llrd\":        [False, True],\n",
        "    \"llrd_decay\":      [0.95],\n",
        "\n",
        "    # ÌïòÎìú ÎÑ§Í±∞Ìã∞Î∏å\n",
        "    \"use_hardneg\":     [False, True],\n",
        "    \"hardneg_tau\":     [0.55],\n",
        "    \"hardneg_boost\":   [2.0],\n",
        "\n",
        "    # ÌèâÍ∞Ä ÏòµÏÖò\n",
        "    \"use_tta\":         [False],   # ÌïÑÏöî Ïãú True Ï∂îÍ∞Ä\n",
        "    \"tta_n\":           [4],\n",
        "}\n",
        "# HP_SPACE = {\n",
        "#     \"lr\": [2e-5],\n",
        "#     \"epochs\": [1],  # Very small for testing\n",
        "#     \"train_bsz\": [16],\n",
        "#     \"max_len\": [256],\n",
        "#     \"scheduler\": [\"cosine\"],\n",
        "#     \"warmup_ratio\": [0.05],\n",
        "#     \"label_smoothing\": [0.0],\n",
        "#     \"marker_variant\": [\"typed\"],\n",
        "#     \"inline_markers\": [True],\n",
        "#     \"use_class_weight\": [False],\n",
        "#     \"use_cb_loss\": [False],\n",
        "#     \"use_focal\": [False],\n",
        "#     \"focal_gamma\": [2.0],\n",
        "#     \"rdrop_alpha\": [0.0],\n",
        "#     \"use_marker_head\": [True],\n",
        "#     \"use_erpe\": [False],\n",
        "#     \"erpe_dim\": [32],\n",
        "#     \"use_fgm\": [False],\n",
        "#     \"fgm_eps\": [1e-3],\n",
        "#     \"use_llrd\": [False],\n",
        "#     \"llrd_decay\": [0.95],\n",
        "#     \"use_hardneg\": [False],\n",
        "#     \"hardneg_tau\": [0.55],\n",
        "#     \"hardneg_boost\": [2.0],\n",
        "#     \"use_tta\": [False],\n",
        "#     \"tta_n\": [4],\n",
        "# }\n",
        "\n",
        "df = run_grid_plus(\n",
        "      train_csv=TRAIN_CSV,\n",
        "      dev_csv=DEV_CSV,\n",
        "      models=MODELS,\n",
        "      hp_space=HP_SPACE,\n",
        "      base_out=\"/content/drive/MyDrive/Colab Notebooks/upstage/grid_runs_plus\",\n",
        "      seed_list=[42],\n",
        "      label_list=DEFAULT_LABEL_LIST,\n",
        ")\n",
        "\n",
        "df.to_csv(\"/content/drive/MyDrive/Colab Notebooks/upstage/dataset/result.csv\")\n",
        "  # ÏÉÅÏúÑ 10Í∞úÎßå Ï∂úÎ†•\n",
        "with pd.option_context('display.max_columns', None):\n",
        "    print(df.head(10))\n",
        "\n",
        "df['error'].iloc[0]\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 486
        },
        "id": "kKSla2jhFoEp",
        "outputId": "b8a9f8bd-2f14-48e0-cee1-64177d69fe3c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of RobertaModel were not initialized from the model checkpoint at klue/roberta-base and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='9140' max='9140' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [9140/9140 10:11, Epoch 10/10]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Micro F1</th>\n",
              "      <th>Auprc</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>1.318800</td>\n",
              "      <td>1.036770</td>\n",
              "      <td>73.521187</td>\n",
              "      <td>63.172521</td>\n",
              "      <td>71.789344</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4000</td>\n",
              "      <td>0.511000</td>\n",
              "      <td>1.091653</td>\n",
              "      <td>75.660932</td>\n",
              "      <td>67.653377</td>\n",
              "      <td>73.544811</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6000</td>\n",
              "      <td>0.272000</td>\n",
              "      <td>1.290736</td>\n",
              "      <td>76.170392</td>\n",
              "      <td>68.476539</td>\n",
              "      <td>74.376347</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8000</td>\n",
              "      <td>0.161000</td>\n",
              "      <td>1.453853</td>\n",
              "      <td>76.194558</td>\n",
              "      <td>67.405558</td>\n",
              "      <td>74.591931</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='102' max='102' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [102/102 00:02]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1/64] done: klue_roberta-base_lr2e-05_ep10_bs32_ml256_mktyped_inline1_mh1_erpe0_ed32_fgm0_cb1_cw0_focal0_rd0.0_llrd0_hn0_tau0.55_boost2.0_seed42 | microF1=None | err=None\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of RobertaModel were not initialized from the model checkpoint at klue/roberta-base and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='2748' max='9140' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [2748/9140 03:03 < 07:07, 14.97 it/s, Epoch 3.01/10]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Micro F1</th>\n",
              "      <th>Auprc</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>1.318800</td>\n",
              "      <td>1.036881</td>\n",
              "      <td>73.478167</td>\n",
              "      <td>63.159498</td>\n",
              "      <td>71.727749</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PDdlC-f_Nggc"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}